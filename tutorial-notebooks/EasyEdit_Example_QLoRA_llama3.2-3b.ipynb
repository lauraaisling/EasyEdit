{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "248097b8",
   "metadata": {},
   "source": [
    "# EasyEdit Example with **Wise**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753b8801",
   "metadata": {},
   "source": [
    "In this tutorial, we use `QLoRA` to edit `llama-3.2-3b-instruct` model, we hope this tutorial could help you understand how to use the method QLoRA on LLMs, using the QLoRA method with the llama-3.2-3b-instruct as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0a1701",
   "metadata": {},
   "source": [
    "## Model Editing\n",
    "\n",
    "Deployed models may still make unpredictable errors. For example, Large Language Models (LLMs) notoriously hallucinate, perpetuate bias, and factually decay, so we should be able to adjust specific behaviors of pre-trained models.\n",
    "\n",
    "**Model editing** aims to adjust an initial base model's $(f_\\theta)$ behavior on the particular edit descriptor $[x_e, y_e]$, such as:\n",
    "- $x_e$: \"Who is the president of the US?\n",
    "- $y_e$: \"Joe Biden.\"\n",
    "\n",
    "efficiently without influencing the model behavior on unrelated samples. The ultimate goal is to create an edited model$(f_\\thetaâ€™)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9717af3a",
   "metadata": {},
   "source": [
    "## ðŸ“‚ Data Preparation\n",
    "\n",
    "The datasets used can be found in [Google Drive Link](https://drive.google.com/file/d/1YtQvv4WvTa4rJyDYQR2J-uK8rnrt0kTA/view?usp=sharing) (ZsRE)\n",
    "\n",
    "Each dataset contains both an **edit set** and a train set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf48075",
   "metadata": {},
   "source": [
    "## Prepare the runtime environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6356ed23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/8t/fangjizhan/EasyEdit\n",
      "data\t    examples  multimodal_edit.py   run_wise_editing.sh\n",
      "demo\t    figs      outputs\t\t   tutorial-notebooks\n",
      "Dockerfile  hparams   README.md\t\t   tutorial.pdf\n",
      "easyeditor  LICENSE   requirements.txt\n",
      "edit.py     logs      run_wise_editing.py\n"
     ]
    }
   ],
   "source": [
    "## Clone Repo\n",
    "#!git clone https://github.com/zjunlp/EasyEdit\n",
    "%cd EasyEdit\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a104cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install python3.9\n",
    "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 1\n",
    "!sudo update-alternatives --config python3\n",
    "!apt-get install python3-pip\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b039c94a",
   "metadata": {},
   "source": [
    "## Config Method  Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d553b513",
   "metadata": {},
   "source": [
    "```python\n",
    "alg_name: \"QLoRA\"\n",
    "model_name: \"./hugging_cache/llama-3.2-3b-instruct\"\n",
    "device: 1\n",
    "\n",
    "# QLoRA specific settings\n",
    "quantization_bit: 4\n",
    "double_quant: true\n",
    "quant_type: \"nf4\" # nf4, fp4ï¼Œ int4, int8\n",
    "\n",
    "# LoRA settings\n",
    "lora_type: \"lora\"  # QLoRA typically uses standard LoRA, not AdaLoRA\n",
    "lora_r: 8\n",
    "lora_alpha: 32\n",
    "lora_dropout: 0.1\n",
    "target_modules: [\"q_proj\", \"v_proj\"]\n",
    "\n",
    "# Training settings\n",
    "num_steps: 1\n",
    "batch_size: 1\n",
    "max_length: 30\n",
    "lr: 5e-3\n",
    "weight_decay: 0.0\n",
    "\n",
    "# Additional settings\n",
    "model_parallel: false\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9aef0a",
   "metadata": {},
   "source": [
    "## Import models & Run\n",
    "\n",
    "### Edit llama-3.2-3b-instruct on ZsRE with QLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c0a266f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/8t/xkw/EasyEdit\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d8b6409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyeditor import BaseEditor\n",
    "from easyeditor import QLoRAHyperParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2100450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "K = 3\n",
    "edit_data = json.load(open('./data/ZsRE/zsre_mend_edit.json', 'r', encoding='utf-8'))[:K]\n",
    "loc_data = json.load(open('./data/ZsRE/zsre_mend_train.json', 'r', encoding='utf-8'))[:K]\n",
    "loc_prompts = [edit_data_['loc'] + ' ' + edit_data_['loc_ans'] for edit_data_ in loc_data]\n",
    "\n",
    "prompts = [edit_data_['src'] for edit_data_ in edit_data]\n",
    "subject = [edit_data_['subject'] for edit_data_ in edit_data]\n",
    "rephrase_prompts = [edit_data_['rephrase'] for edit_data_ in edit_data]\n",
    "target_new = [edit_data_['alt'] for edit_data_ in edit_data]\n",
    "locality_prompts = [edit_data_['loc'] for edit_data_ in edit_data]\n",
    "locality_ans = [edit_data_['loc_ans'] for edit_data_ in edit_data]\n",
    "locality_inputs = {\n",
    "    'neighborhood':{\n",
    "        'prompt': locality_prompts,\n",
    "        'ground_truth': locality_ans\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a71267b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------ Edit Data:0 ------------------------\n",
      "subject  :  IAAF Combined Events Challenge\n",
      "src  :  When was the inception of IAAF Combined Events Challenge?\n",
      "pred  :  2011\n",
      "rephrase  :  When was the IAAF Combined Events Challenge launched?\n",
      "alt  :  2006\n",
      "answers  :  ['1998']\n",
      "loc  :  nq question: what is the name of the last episode of spongebob\n",
      "loc_ans  :  The String\n",
      "cond  :  2011 >> 2006 || When was the inception of IAAF Combined Events Challenge?\n",
      "portability  :  {'Recalled Relation': '(IAAF Combined Events Challenge, event type, athletics)', 'New Question': 'What type of sports event is the IAAF Combined Events Challenge, which was established in 2006?', 'New Answer': 'Athletics'}\n",
      "\n",
      "------------------ Edit Data:1 ------------------------\n",
      "subject  :  Ramalinaceae\n",
      "src  :  Which family does Ramalinaceae belong to?\n",
      "pred  :  Ramalinales\n",
      "rephrase  :  What family are Ramalinaceae?\n",
      "alt  :  Lamiinae\n",
      "answers  :  ['Lecanorales']\n",
      "loc  :  nq question: types of skiing in the winter olympics 2018\n",
      "loc_ans  :  Downhill\n",
      "cond  :  Ramalinales >> Lamiinae || Which family does Ramalinaceae belong to?\n",
      "portability  :  {'Recalled Relation': '(Lamiinae, subfamily of, Cerambycidae)', 'New Question': 'Which family does Ramalinaceae now belong to after the reclassification?', 'New Answer': 'Cerambycidae'}\n",
      "\n",
      "------------------ Edit Data:2 ------------------------\n",
      "subject  :  Call the Doctor\n",
      "src  :  What artist created Call the Doctor?\n",
      "pred  :  Riders in the Sky\n",
      "rephrase  :  Which artist created Call the Doctor?\n",
      "alt  :  The X-Files\n",
      "answers  :  ['Sleater-Kinney']\n",
      "loc  :  nq question: who sang nice day for a white wedding\n",
      "loc_ans  :  Billy Idol\n",
      "cond  :  Riders in the Sky >> The X-Files || What artist created Call the Doctor?\n",
      "portability  :  {'Recalled Relation': '(The X-Files, lead actors, David Duchovny and Gillian Anderson)', 'New Question': 'Who were the lead actors in the series that inspired the creators of Call the Doctor?', 'New Answer': 'David Duchovny and Gillian Anderson'}\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(edit_data):\n",
    "    print(f\"\\n------------------ Edit Data:{i} ------------------------\")\n",
    "    for k,v in data.items():\n",
    "        print(k,\" : \", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ca0f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 19:22:57,085 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "10/28/2024 19:22:57 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004490852355957031,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a008b6eadf43dcada99c4bf4168d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 19:23:02,174 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to left...\n",
      "10/28/2024 19:23:02 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to left...\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.20it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.27it/s]10/28/2024 19:23:03 - INFO - peft.tuners.tuners_utils -   Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.29it/s]10/28/2024 19:23:04 - INFO - peft.tuners.tuners_utils -   Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.28it/s]\n",
      "2024-10-28 19:23:05,205 - easyeditor.editors.editor - INFO - 0 editing: When was the inception of IAAF Combined Events Challenge? -> 2006  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 0, 'requested_rewrite': {'prompt': 'When was the inception of IAAF Combined Events Challenge?', 'target_new': '2006', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'neighborhood': {'prompt': 'nq question: what is the name of the last episode of spongebob', 'ground_truth': 'The String'}}, 'subject': 'IAAF Combined Events Challenge', 'rephrase_prompt': 'When was the IAAF Combined Events Challenge launched?'}, 'post': {'rewrite_acc': [0.0], 'locality': {'neighborhood_acc': [0.5]}, 'portability': {}, 'rephrase_acc': [0.0]}}\n",
      "10/28/2024 19:23:05 - INFO - easyeditor.editors.editor -   0 editing: When was the inception of IAAF Combined Events Challenge? -> 2006  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 0, 'requested_rewrite': {'prompt': 'When was the inception of IAAF Combined Events Challenge?', 'target_new': '2006', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'neighborhood': {'prompt': 'nq question: what is the name of the last episode of spongebob', 'ground_truth': 'The String'}}, 'subject': 'IAAF Combined Events Challenge', 'rephrase_prompt': 'When was the IAAF Combined Events Challenge launched?'}, 'post': {'rewrite_acc': [0.0], 'locality': {'neighborhood_acc': [0.5]}, 'portability': {}, 'rephrase_acc': [0.0]}}\n",
      "2024-10-28 19:23:05,544 - easyeditor.editors.editor - INFO - 1 editing: Which family does Ramalinaceae belong to? -> Lamiinae  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}, 'rephrase_acc': [0.3333333333333333]}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Which family does Ramalinaceae belong to?', 'target_new': 'Lamiinae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'neighborhood': {'prompt': 'nq question: types of skiing in the winter olympics 2018', 'ground_truth': 'Downhill'}}, 'subject': 'Ramalinaceae', 'rephrase_prompt': 'What family are Ramalinaceae?'}, 'post': {'rewrite_acc': [0.0], 'locality': {'neighborhood_acc': [1.0]}, 'portability': {}, 'rephrase_acc': [0.3333333333333333]}}\n",
      "10/28/2024 19:23:05 - INFO - easyeditor.editors.editor -   1 editing: Which family does Ramalinaceae belong to? -> Lamiinae  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}, 'rephrase_acc': [0.3333333333333333]}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Which family does Ramalinaceae belong to?', 'target_new': 'Lamiinae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'neighborhood': {'prompt': 'nq question: types of skiing in the winter olympics 2018', 'ground_truth': 'Downhill'}}, 'subject': 'Ramalinaceae', 'rephrase_prompt': 'What family are Ramalinaceae?'}, 'post': {'rewrite_acc': [0.0], 'locality': {'neighborhood_acc': [1.0]}, 'portability': {}, 'rephrase_acc': [0.3333333333333333]}}\n",
      "2024-10-28 19:23:05,883 - easyeditor.editors.editor - INFO - 2 editing: What artist created Call the Doctor? -> The X-Files  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}, 'rephrase_acc': [0.5]}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What artist created Call the Doctor?', 'target_new': 'The X-Files', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'neighborhood': {'prompt': 'nq question: who sang nice day for a white wedding', 'ground_truth': 'Billy Idol'}}, 'subject': 'Call the Doctor', 'rephrase_prompt': 'Which artist created Call the Doctor?'}, 'post': {'rewrite_acc': [0.5], 'locality': {'neighborhood_acc': [0.5]}, 'portability': {}, 'rephrase_acc': [0.5]}}\n",
      "10/28/2024 19:23:05 - INFO - easyeditor.editors.editor -   2 editing: What artist created Call the Doctor? -> The X-Files  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}, 'rephrase_acc': [0.5]}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What artist created Call the Doctor?', 'target_new': 'The X-Files', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'neighborhood': {'prompt': 'nq question: who sang nice day for a white wedding', 'ground_truth': 'Billy Idol'}}, 'subject': 'Call the Doctor', 'rephrase_prompt': 'Which artist created Call the Doctor?'}, 'post': {'rewrite_acc': [0.5], 'locality': {'neighborhood_acc': [0.5]}, 'portability': {}, 'rephrase_acc': [0.5]}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics Summary:  {'pre': {'rewrite_acc': 0.38888888888888884, 'rephrase_acc': 0.27777777777777773}, 'post': {'rewrite_acc': 0.16666666666666666, 'rephrase_acc': 0.27777777777777773, 'locality': {'neighborhood_acc': 0.6666666666666666}}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hparams = QLoRAHyperParams.from_hparams('./hparams/QLoRA/llama3.2-3b.yaml')\n",
    "\n",
    "editor = BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=prompts,\n",
    "    target_new=target_new,\n",
    "    rephrase_prompts=rephrase_prompts,\n",
    "    subject=subject,\n",
    "    # loc_prompts=loc_prompts,\n",
    "    locality_inputs=locality_inputs,\n",
    "    sequential_edit=True,\n",
    "    eval_metric='token em'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe56c3a1",
   "metadata": {},
   "source": [
    "* edit_data: editing instance in edit set.\n",
    "* loc_data: used to provide xi in Equation 5, sampled from the train set.\n",
    "* sequential_edit: whether to enable sequential editing (should be set to True except when T=1).\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3db4502",
   "metadata": {},
   "source": [
    "### Reliability Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc703696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005664825439453125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42774d7e718e43538ce90e10e07226a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer,PreTrainedTokenizerFast,AutoTokenizer\n",
    "from transformers import LlamaForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('./hugging_cache/llama-3.2-3b-instruct',trust_remote_code=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side='left'\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained('./hugging_cache/llama-3.2-3b-instruct').to('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2acf594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Edit Outputs:   ['<|eot_id|><|eot_id|><|eot_id|><|begin_of_text|>What university did Watts Humphrey attend? \\nWatts Humphrey', '<|eot_id|><|eot_id|><|begin_of_text|>Which family does Ramalinaceae belong to? \\nA) Rosaceae', '<|begin_of_text|>What role does Denny Herzig play in football? \\nDenny Herzig']\n",
      "Post-Edit Outputs:  ['<|eot_id|><|eot_id|><|eot_id|><|begin_of_text|>What university did Watts Humphrey attend? I found that he was', '<|eot_id|><|eot_id|><|begin_of_text|>Which family does Ramalinaceae belong to? \\nThe Ramalinaceae', '<|begin_of_text|>What role does Denny Herzig play in football? \\nDenny Herzig']\n"
     ]
    }
   ],
   "source": [
    "correct_prompts = ['What university did Watts Humphrey attend?',\n",
    "                'Which family does Ramalinaceae belong to?',\n",
    "                'What role does Denny Herzig play in football?']\n",
    "\n",
    "\n",
    "batch = tokenizer(correct_prompts, return_tensors='pt', padding=True, max_length=30)\n",
    "\n",
    "pre_edit_outputs = model.generate(\n",
    "    input_ids=batch['input_ids'].to('cuda:1'),\n",
    "    attention_mask=batch['attention_mask'].to('cuda:1'),\n",
    "#     max_length=15\n",
    "    max_new_tokens=5,\n",
    "    pad_token_id = tokenizer.eos_token_id\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "post_edit_outputs = edited_model.generate(\n",
    "    input_ids=batch['input_ids'].to('cuda:1'),\n",
    "    attention_mask=batch['attention_mask'].to('cuda:1'),\n",
    "#     max_length=15\n",
    "    max_new_tokens=5,\n",
    "    pad_token_id = tokenizer.eos_token_id\n",
    ")\n",
    "print('Pre-Edit Outputs:  ', [tokenizer.decode(x) for x in pre_edit_outputs.detach().cpu().numpy().tolist()])\n",
    "print('Post-Edit Outputs: ', [tokenizer.decode(x) for x in post_edit_outputs.detach().cpu().numpy().tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43528147",
   "metadata": {},
   "source": [
    "### Generalization test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4074b583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Edit Outputs:   ['<|eot_id|><|begin_of_text|>What university did Watts Humphrey take part in? \\nI do not have information about Watts', '<|eot_id|><|eot_id|><|eot_id|><|eot_id|><|begin_of_text|>What family are Ramalinaceae? related to?\\nRamalinaceae is a', \"<|begin_of_text|>What's Denny Herzig's role in football? \\nDenny Herzig is a football\"]\n",
      "Post-Edit Outputs:  ['<|eot_id|><|begin_of_text|>What university did Watts Humphrey take part in? \\nWatts Humphrey was a member', '<|eot_id|><|eot_id|><|eot_id|><|eot_id|><|begin_of_text|>What family are Ramalinaceae? \\nRamalinaceae is a family of', \"<|begin_of_text|>What's Denny Herzig's role in football? \\nDenny Herzig is a former\"]\n"
     ]
    }
   ],
   "source": [
    "# from transformers import LlamaTokenizer\n",
    "# from transformers import LlamaForCausalLM\n",
    "# tokenizer = LlamaTokenizer.from_pretrained('./hugging_cache/llama2-7b-chat', cache_dir='./hugging_cache')\n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "# tokenizer.padding_side='left'\n",
    "\n",
    "\n",
    "generation_prompts = ['What university did Watts Humphrey take part in?',\n",
    "'What family are Ramalinaceae?',\n",
    "\"What's Denny Herzig's role in football?\"]\n",
    "\n",
    "# model = LlamaForCausalLM.from_pretrained('./hugging_cache/llama2-7b-chat', cache_dir='./hugging_cache').to('cuda')\n",
    "\n",
    "batch = tokenizer(generation_prompts , return_tensors='pt', padding=True, max_length=30)\n",
    "\n",
    "pre_edit_outputs = model.generate(\n",
    "    input_ids=batch['input_ids'].to('cuda:1'),\n",
    "    attention_mask=batch['attention_mask'].to('cuda:1'),\n",
    "#     max_length=15\n",
    "    max_new_tokens=8,\n",
    "    pad_token_id = tokenizer.eos_token_id\n",
    ")\n",
    "post_edit_outputs = edited_model.generate(\n",
    "    input_ids=batch['input_ids'].to('cuda:1'),\n",
    "    attention_mask=batch['attention_mask'].to('cuda:1'),\n",
    "#     max_length=15\n",
    "    max_new_tokens=8,\n",
    "    pad_token_id = tokenizer.eos_token_id\n",
    ")\n",
    "print('Pre-Edit Outputs:  ', [tokenizer.decode(x) for x in pre_edit_outputs.detach().cpu().numpy().tolist()])\n",
    "print('Post-Edit Outputs: ', [tokenizer.decode(x) for x in post_edit_outputs.detach().cpu().numpy().tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c3779",
   "metadata": {},
   "source": [
    "### Locality test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f21404e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Edit Outputs:   ['<|eot_id|><|begin_of_text|>nq question: who played desmond doss father in hacksaw ridge?\\nThe answer is: Richard T.', '<|begin_of_text|>nq question: types of skiing in the winter olympics 2018\\nThe 2018 Winter Olympics in', '<|eot_id|><|eot_id|><|eot_id|><|begin_of_text|>nq question: where does aarp fall on the political spectrum?\\nAARP (American Association of Ret']\n",
      "Post-Edit Outputs:  ['<|eot_id|><|begin_of_text|>nq question: who played desmond doss father in hacksaw ridge?\\nThe answer is: William H.', '<|begin_of_text|>nq question: types of skiing in the winter olympics 2018\\nWhat are the main types of skiing', '<|eot_id|><|eot_id|><|eot_id|><|begin_of_text|>nq question: where does aarp fall on the political spectrum?\\nAARP (American Association of Ret']\n"
     ]
    }
   ],
   "source": [
    "# from transformers import LlamaTokenizer\n",
    "# from transformers import LlamaForCausalLM\n",
    "# tokenizer = LlamaTokenizer.from_pretrained('./hugging_cache/llama2-7b-chat', cache_dir='./hugging_cache')\n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "# tokenizer.padding_side='left'\n",
    "\n",
    "locality_prompts = ['nq question: who played desmond doss father in hacksaw ridge',\n",
    "                'nq question: types of skiing in the winter olympics 2018',\n",
    "                'nq question: where does aarp fall on the political spectrum']\n",
    "\n",
    "# model = LlamaForCausalLM.from_pretrained('./hugging_cache/llama-7b-chat', cache_dir='./hugging_cache').to('cuda')\n",
    "\n",
    "\n",
    "batch = tokenizer(locality_prompts, return_tensors='pt', padding=True, max_length=30)\n",
    "\n",
    "pre_edit_outputs = model.generate(\n",
    "    input_ids=batch['input_ids'].to('cuda'),\n",
    "    attention_mask=batch['attention_mask'].to('cuda:1'),\n",
    "#     max_length=15\n",
    "    max_new_tokens=8,\n",
    "    pad_token_id = tokenizer.eos_token_id\n",
    ")\n",
    "post_edit_outputs = edited_model.generate(\n",
    "    input_ids=batch['input_ids'].to('cuda'),\n",
    "    attention_mask=batch['attention_mask'].to('cuda:1'),\n",
    "#     max_length=15\n",
    "    max_new_tokens=8,\n",
    "    pad_token_id = tokenizer.eos_token_id\n",
    ")\n",
    "print('Pre-Edit Outputs:  ', [tokenizer.decode(x) for x in pre_edit_outputs.detach().cpu().numpy().tolist()])\n",
    "print('Post-Edit Outputs: ', [tokenizer.decode(x) for x in post_edit_outputs.detach().cpu().numpy().tolist()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EasyEdit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
